{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the sampling patch image information and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "patch_size = 256\n",
    "image_size = patch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os,sys,random,cv2,re\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import tifffile\n",
    "from tensorflow import keras\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from tensorflow import reduce_sum\n",
    "from tensorflow.keras.backend import pow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add, Flatten\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling patch for all the input image(output 270 pieces for both labels and images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDir = \"Train/original_retinal_images/\"\n",
    "labelDir = \"Train/masks_Haemorrhages/\"\n",
    "def patchDiv(imgPath,labelPath,patchSize=256):\n",
    "    #loop through image and label\n",
    "    images = os.listdir(imageDir)\n",
    "    labels = os.listdir(labelDir)\n",
    "    imagePatch = []\n",
    "    labelPatch = []\n",
    "    count = 1\n",
    "    for i in images:\n",
    "        name = i.split('.')[0]\n",
    "        imageLabel = labelPath + name + \"_HE.tif\"\n",
    "        img = cv2.imread(imgPath + i,0)\n",
    "        label = cv2.imread(imageLabel,0)\n",
    "        img = np.expand_dims(img,axis=2)\n",
    "        label = np.expand_dims(label,axis=2)     \n",
    "        cutW = img.shape[0]//patchSize\n",
    "        cutH = img.shape[1]//patchSize\n",
    "        #divide image into patch\n",
    "        for w in range(0, (cutW * 10 // 2) + 5, 5):\n",
    "            for h in range(0, (cutH * 10 // 2) + 5, 5):\n",
    "                imagePatch.append(img[int((w/10)*patchSize):int(((w/10)+1)*patchSize), int((h/10)*patchSize):int(((h/10)+1)*patchSize)])\n",
    "                labelPatch.append(label[int((w/10)*patchSize):int(((w/10)+1)*patchSize), int((h/10)*patchSize):int(((h/10)+1)*patchSize)])\n",
    "    return imagePatch,labelPatch\n",
    "imgP,labeP = patchDiv(imageDir,labelDir,patchSize=patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the first all of images and label that belong to first images and label.(For checking sampling patch is correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(100,100))\n",
    "# images = imgP[162:171]#os.listdir(imageDir)\n",
    "# labels = labeP[162:171]#os.listdir(labelDir)\n",
    "\n",
    "# for i in range(len(images)):\n",
    "#     plt.subplot(len(images),len(labels),i+1)\n",
    "#     plt.imshow(images[i][:,:,0],'gray')\n",
    "#     plt.subplot(len(images),len(labels),i+len(images)+1)\n",
    "#     plt.imshow(labels[i][:,:,0],'gray')\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and validation.(Inorder to using validation when training the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,validX,trainY,validY = train_test_split(imgP,labeP,train_size=0.8, random_state = 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data augmentation part.(All the patch that split by sampling patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 数据增强 Data augmentation的参数\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        if flag_multi_class:\n",
    "            img = labelVisualize(num_class,COLOR_DICT,item)\n",
    "        else:\n",
    "            img=item[:,:,0]\n",
    "            print(np.max(img),np.min(img))\n",
    "            img[img>0.5]=1#此时1是浮点数，下面的0也是\n",
    "            img[img<=0.5]=0\n",
    "            print(np.max(img),np.min(img))\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
    "\n",
    "def adjustData(img,mask,flag_multi_class,num_class):\n",
    "    if(np.max(img) > 1):\n",
    "        #divided by 255 to convert to probability image\n",
    "        img = img / 255\n",
    "        mask = mask /255\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='reflect')\n",
    "\n",
    "def trainGenerator(batch_size,trainImage,trainLable,aug_dict,image_color_mode = \"grayscale\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    \n",
    "    image_generator = image_datagen.flow(\n",
    "        x = np.array(trainImage),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        seed = seed,\n",
    "        save_to_dir = save_to_dir \n",
    "    )\n",
    "    mask_generator = mask_datagen.flow(\n",
    "        x = np.array(trainLable),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        seed = seed,\n",
    "        save_to_dir = save_to_dir \n",
    "    )\n",
    "\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        yield (img,mask)\n",
    "        \n",
    "myGene = trainGenerator(batch_size,trainX,trainY,data_gen_args,save_to_dir = None)\n",
    "myValid = trainGenerator(batch_size,validX,validY,data_gen_args,save_to_dir = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(x,filters,kernel_size=(3,3),padding='same',strides=1):\n",
    "    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(x)\n",
    "    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(c)\n",
    "    p=keras.layers.MaxPool2D((2,2),(2,2))(c)\n",
    "    return c,p\n",
    "def up_block(x,skip,filters,kernel_size=(3,3),padding='same',strides=1):\n",
    "    us=keras.layers.UpSampling2D((2,2))(x)\n",
    "    concat=keras.layers.concatenate([us,skip],axis=3)\n",
    "    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(concat)\n",
    "    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(c)\n",
    "    return c\n",
    "def bottleNeck(x,filters,kernel_size=(3,3),padding='same',strides=1):\n",
    "    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(x)\n",
    "    c=keras.layers.Conv2D(filters,kernel_size,padding=padding,strides=strides,activation='relu')(c)\n",
    "    return c\n",
    "def Unet():\n",
    "    f = [64,128,256,512,1024]#feature maps, number of filters\n",
    "    inputs=keras.layers.Input((image_size,image_size,1))#input to the model\n",
    "    p0 = inputs\n",
    "    c1,p1 = down_block(p0,f[0])#1->64\n",
    "    c2,p2 = down_block(p1,f[1])#64->128\n",
    "    c3,p3 = down_block(p2,f[2])#128->256\n",
    "    c4,p4 = down_block(p3,f[3])#256->512\n",
    "    drop1 = keras.layers.Dropout(0.5)(p4)\n",
    "    \n",
    "    bn = bottleNeck(drop1,f[4])#512->1024\n",
    "    drop2 = keras.layers.Dropout(0.5)(bn)\n",
    "\n",
    "    u1 = up_block(drop2,c4,f[3])#1024->512\n",
    "    u2 = up_block(u1,c3,f[2])#512->256\n",
    "    u3 = up_block(u2,c2,f[1])#256->128\n",
    "    u4 = up_block(u3,c1,f[0])#128->64\n",
    "    \n",
    "    outputs_up = keras.layers.Conv2D(2,(3,3),padding=\"same\",activation=\"relu\")(u4)#64->2\n",
    "    outputs = keras.layers.Conv2D(1,(1,1),padding=\"same\",activation=\"sigmoid\")(outputs_up)#2->1\n",
    "    print(\"output\",outputs.shape)\n",
    "    model = keras.models.Model(inputs,outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Unet(pretrained_weights = None,input_size = (256, 256, 1)):\n",
    "#     inputs = keras.layers.Input(input_size)\n",
    "#     conv1 = keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "#     conv1 = keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "#     pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "#     conv2 = keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "#     conv2 = keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "#     pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "#     conv3 = keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "#     conv3 = keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "#     pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "#     conv4 = keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "#     conv4 = keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "#     drop4 = keras.layers.Dropout(0.5)(conv4)\n",
    "#     pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "#     conv5 = keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "#     conv5 = keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "#     drop5 = keras.layers.Dropout(0.5)(conv5)\n",
    "\n",
    "#     up6 = keras.layers.Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "#     merge6 = keras.layers.concatenate([drop4,up6], axis = 3)\n",
    "#     conv6 = keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "#     conv6 = keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "#     up7 = keras.layers.Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "#     merge7 = keras.layers.concatenate([conv3,up7], axis = 3)\n",
    "#     conv7 = keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "#     conv7 = keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "#     up8 = keras.layers.Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "#     merge8 = keras.layers.concatenate([conv2,up8], axis = 3)\n",
    "#     conv8 = keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "#     conv8 = keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "#     up9 = keras.layers.Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "#     merge9 = keras.layers.concatenate([conv1,up9], axis = 3)\n",
    "#     conv9 = keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "#     conv9 = keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "#     conv9 = keras.layers.Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "#     conv10 = keras.layers.Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "#     model = keras.models.Model(inputs,conv10)\n",
    "\n",
    "#     model.compile(optimizer = Adam(lr = 1e-4), loss = bce_dice_loss, metrics = ['accuracy', dice_coef])\n",
    "#     #model.compile(optimizer = Adam(lr = 1e-4), loss = focal_loss(gamma=2,alpha=0.6), metrics = ['accuracy', dice_coef])\n",
    "#     #model.compile(optimizer = Adam(lr = 1e-4), loss = focal_dice_loss, metrics = ['accuracy', dice_coef])\n",
    "    \n",
    "#     if(pretrained_weights):\n",
    "#         model.load_weights(pretrained_weights)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function(Dice coefficeient and binary cross Dice coefficeient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth = 1):\n",
    "    return 1- dice_coef(y_true, y_pred, smooth)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred, weight = 1, smooth = 1):\n",
    "    '''\n",
    "    bce + w*dice loss\n",
    "    '''\n",
    "    return binary_crossentropy(y_true, y_pred) + weight*dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet()\n",
    "opt = keras.optimizers.Adam(lr=1e-4)\n",
    "model.compile(optimizer=opt, loss=bce_dice_loss, metrics=[\"acc\"])#metrics=[dsc]\n",
    "trainStep = (len(trainX)//40)//batch_size\n",
    "validStep = (len(validX)//40)//batch_size\n",
    "print(trainStep)\n",
    "print(validStep)\n",
    "history = model.fit_generator(myGene,steps_per_epoch=trainStep,epochs=1,validation_data=myValid,validation_steps=validStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out for the train loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_final_history(history):\n",
    "    fig= plt.figure(figsize=(10,10))\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    plt.legend()\n",
    "    fig= plt.figure(figsize=(10,10))\n",
    "    plt.title('Acc')\n",
    "    plt.plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n",
    "    plt.plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n",
    "    plt.legend()\n",
    "    fig= plt.figure(figsize=(10,10))\n",
    "show_final_history(history)\n",
    "print(\"Validation Accuracy: \" + str(history.history['val_acc'][-1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestList = [\"Test/original_retinal_images/\"+\"IDRiD_\"+ str(i)+ \".jpg\" for i in range(55,82)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestDataGenerator(imglist,target_size = (256,256),flag_multi_class = False):\n",
    "    for i in imglist:\n",
    "        img = cv2.imread(i,0)\n",
    "        img = img / 255.0\n",
    "        img = trans.resize(img,target_size)\n",
    "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "#将测试图片扩展一个维度，与训练时的输入[2,256,256]保持一致\n",
    "        yield img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestDataGenerator(imageList,patchSize=256):\n",
    "    for img in imageList:\n",
    "        x = cv2.imread(img,0)#256,256\n",
    "        x = trans.resize(x,(256,256))\n",
    "        x = np.expand_dims(x,axis=2)#256,256,1\n",
    "        x = np.expand_dims(x,axis=0)#1,256,256,1\n",
    " \n",
    "        yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "testGene = TestDataGenerator(TestList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The part that merge all the pieces that split by sampling patch into a completed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the result \n",
    "def mergeResult(imageList,originalImageShape=512,patchSize=256):\n",
    "    #index: number of elements in the input list for one image\n",
    "    cut = (originalImageShape//patchSize) + 1 #512 / 256 + 1 = 3\n",
    "    index = cut * cut\n",
    "    count = 0\n",
    "    i = 0\n",
    "    print(len(imageList))\n",
    "    mergedResult = np.zeros((len(imageList)//index, ) + (originalImageShape,originalImageShape,1))\n",
    "    while(count + index <= len(imageList)):#(9,18,27...) <= 270\n",
    "        vstacked = []\n",
    "        temp = imageList[count:count + index]#[0:9]\n",
    "        flag = 0\n",
    "        hstacked_list = []\n",
    "        for h in range(cut,index + 1, 3):#(2-4)\n",
    "            tmp = []\n",
    "            tmp2 = []\n",
    "            for r in range(flag,flag + cut):#(0-2),(2-4)\n",
    "                tmp.append(temp[r][:,:128,:])\n",
    "                tmp.append(temp[r][:,128:256,:])\n",
    "            tmp2.append(tmp[0])\n",
    "            tmp2.append((tmp[1] + tmp[2]) / 2)\n",
    "            tmp2.append((tmp[3] + tmp[4]) / 2)\n",
    "            tmp2.append(tmp[5])\n",
    "            \n",
    "            for k in range(len(tmp2)):\n",
    "                hstacked = tmp2[k] if(k == 0) else np.hstack((hstacked,tmp2[k]))\n",
    "            hstacked_list.append(hstacked)\n",
    "            flag = h\n",
    "            \n",
    "        vtmp = []\n",
    "        vtmp2 = []\n",
    "        for j in range(len(hstacked_list)):\n",
    "            vtmp.append(hstacked_list[j][:128,:,:])\n",
    "            vtmp.append(hstacked_list[j][128:256,:,:])\n",
    "        vtmp2.append(vtmp[0])\n",
    "        vtmp2.append((vtmp[1] + vtmp[2]) / 2)\n",
    "        vtmp2.append((vtmp[3] + vtmp[4]) / 2)\n",
    "        vtmp2.append(vtmp[5])\n",
    "        for l in range(len(vtmp2)):\n",
    "            vstacked = vtmp2[l] if (len(vstacked)==0) else np.vstack((vstacked,vtmp2[l]))\n",
    "        count += index\n",
    "        mergedResult[i] = vstacked\n",
    "        i += 1 \n",
    "    return mergedResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your dataset iterator ran out of data; interrupting training. Make sure that your iterator can generate at least `steps * epochs` batches (in this case, 225 batches). You may need touse the repeat() function when building your dataset.\n"
     ]
    }
   ],
   "source": [
    "result = model.predict_generator(testGene,steps=26,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveResult(\"output\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
